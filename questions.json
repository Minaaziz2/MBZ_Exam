{
  "sections": [
    {
      "id": "linear-algebra",
      "title": "Linear Algebra",
      "questions": [
        {
          "id": 1,
          "text": "Given matrix A ∈ ℝ^(4×6) with rank 3, what is the dimension of the null space?",
          "options": ["A) 1", "B) 2", "C) 3", "D) 4"],
          "correct": "C",
          "explanation": "By rank-nullity theorem: dim(Null(A)) = n - rank(A) = 6 - 3 = 3"
        },
        {
          "id": 2,
          "text": "Which condition ensures two vectors u and v are linearly independent?",
          "options": ["A) u · v = 0", "B) ||u|| = ||v||", "C) au + bv = 0 implies a = b = 0", "D) u and v are orthogonal"],
          "correct": "C",
          "explanation": "Definition of linear independence"
        },
        {
          "id": 3,
          "text": "For an upper triangular matrix, the eigenvalues are:",
          "options": ["A) Always positive", "B) The diagonal entries", "C) Always real", "D) The off-diagonal entries"],
          "correct": "B",
          "explanation": "For triangular matrices, eigenvalues are the diagonal elements"
        },
        {
          "id": 4,
          "text": "If A is a symmetric matrix, then A^T A has eigenvalues that are:",
          "options": ["A) Always negative", "B) Always non-negative", "C) Complex conjugates", "D) Equal to those of A"],
          "correct": "D",
          "explanation": "Since A = A^T, we have A^T A = A²"
        },
        {
          "id": 5,
          "text": "The singular values of matrix A are:",
          "options": ["A) Eigenvalues of A", "B) Square roots of eigenvalues of A^T A", "C) Diagonal entries of A", "D) Eigenvalues of AA^T"],
          "correct": "B",
          "explanation": "Definition of singular values"
        }
      ]
    },
    {
      "id": "calculus",
      "title": "Calculus & Optimization",
      "questions": [
        {
          "id": 26,
          "text": "The gradient ∇f(x,y) = (2x, 2y) corresponds to function:",
          "options": ["A) f(x,y) = x² + y²", "B) f(x,y) = 2x + 2y", "C) f(x,y) = x² + y² + C", "D) Both A and C"],
          "correct": "D",
          "explanation": "Gradients differ by constants"
        },
        {
          "id": 27,
          "text": "The Hessian matrix contains:",
          "options": ["A) First-order partial derivatives", "B) Second-order partial derivatives", "C) Mixed derivatives only", "D) Eigenvalues"],
          "correct": "B",
          "explanation": "Hessian contains second-order partial derivatives"
        }
      ]
    },
    {
      "id": "probability",
      "title": "Probability Theory",
      "questions": [
        {
          "id": 46,
          "text": "For independent events A and B, P(A ∩ B) equals:",
          "options": ["A) P(A) + P(B)", "B) P(A) × P(B)", "C) P(A) - P(B)", "D) P(A) / P(B)"],
          "correct": "B",
          "explanation": "Definition of independence"
        }
      ]
    },
    {
      "id": "statistics",
      "title": "Statistics & Inference", 
      "questions": [
        {
          "id": 66,
          "text": "The maximum likelihood estimator (MLE) maximizes:",
          "options": ["A) The posterior probability", "B) The likelihood function", "C) The prior probability", "D) The sample variance"],
          "correct": "B",
          "explanation": "MLE maximizes L(θ|data)"
        }
      ]
    },
    {
      "id": "ml-fundamentals",
      "title": "Machine Learning Fundamentals",
      "questions": [
        {
          "id": 81,
          "text": "The bias-variance tradeoff states that test error equals:",
          "options": ["A) Bias + Variance", "B) Bias² + Variance + Irreducible Error", "C) Bias × Variance", "D) Bias - Variance"],
          "correct": "B",
          "explanation": "Bias-variance decomposition"
        }
      ]
    }
  ]
}
